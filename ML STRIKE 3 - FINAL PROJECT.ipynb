{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Team Name ML Strike 3\n",
    "### Team members:\n",
    "### Akash guje c0835384\n",
    "### Noah David c0846073\n",
    "### Naman shah c0853267\n",
    "### Lakhvir singh c0851353\n",
    "\n",
    "### AML3304 Software tools and emerging Technologies \n",
    "### Final project code "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NBL1KfRTjZJx",
    "outputId": "30e6cc12-c894-4b08-9028-a487360b2795"
   },
   "source": [
    "# Importing Libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "dTLYub9YjaQI"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-21 19:09:39.003814: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/love/my_ws/devel/lib:/opt/ros/noetic/lib\n",
      "2023-04-21 19:09:39.003841: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-04-21 19:09:53.448618: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/love/my_ws/devel/lib:/opt/ros/noetic/lib\n",
      "2023-04-21 19:09:53.448930: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/love/my_ws/devel/lib:/opt/ros/noetic/lib\n",
      "2023-04-21 19:09:53.448954: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "VWNGLq3ox8_H"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "x0QGInUcx_7z"
   },
   "outputs": [],
   "source": [
    "\n",
    "# load the text data\n",
    "with open('145-0.txt', 'r') as f:\n",
    "    text = f.read().lower()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre processing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "Yg0-c1acyIXI"
   },
   "outputs": [],
   "source": [
    "# create a mapping of characters to integers\n",
    "chars = sorted(list(set(text)))\n",
    "char_to_int = dict((c, i) for i, c in enumerate(chars))\n",
    "int_to_char = dict((i, c) for i, c in enumerate(chars))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "V6lGKBh_yTEV"
   },
   "outputs": [],
   "source": [
    "# prepare the dataset of input to output pairs encoded as integers\n",
    "seq_length = 100\n",
    "dataX = []\n",
    "dataY = []\n",
    "for i in range(0, len(text) - seq_length, 1):\n",
    "    seq_in = text[i:i + seq_length]\n",
    "    seq_out = text[i + seq_length]\n",
    "    dataX.append([char_to_int[char] for char in seq_in])\n",
    "    dataY.append(char_to_int[seq_out])\n",
    "n_patterns = len(dataX)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reshaping and normalizing input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1R1CAWg3yVSZ"
   },
   "outputs": [],
   "source": [
    "# reshape X to be [samples, time steps, features]\n",
    "X = np.reshape(dataX, (n_patterns, seq_length, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8UgY3W9ByktA"
   },
   "outputs": [],
   "source": [
    "# normalize the input data\n",
    "X = X / float(len(chars))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One hot encoding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JfzUllMlyo3d"
   },
   "outputs": [],
   "source": [
    "# one hot encode the output variable\n",
    "y = tf.keras.utils.to_categorical(dataY)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "2vyAlGzjyr0m"
   },
   "outputs": [],
   "source": [
    "# define the LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(X.shape[1], X.shape[2])))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s7udUZSwyu_M",
    "outputId": "30dd391e-3e16-41b5-9bbf-99036eceed29"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "14056/14056 [==============================] - 3831s 273ms/step - loss: 2.7804\n",
      "Epoch 2/6\n",
      "14056/14056 [==============================] - 3810s 271ms/step - loss: 2.5990\n",
      "Epoch 3/6\n",
      "14056/14056 [==============================] - 3789s 270ms/step - loss: 2.4766\n",
      "Epoch 4/6\n",
      "14056/14056 [==============================] - 3808s 271ms/step - loss: 2.3930\n",
      "Epoch 5/6\n",
      "14056/14056 [==============================] - 3833s 273ms/step - loss: 2.3336\n",
      "Epoch 6/6\n",
      "14056/14056 [==============================] - 3857s 274ms/step - loss: 2.2891\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8e50ff8190>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train the model\n",
    "model.fit(X, y, epochs=6, batch_size=128)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QdGoTxzv_1UE",
    "outputId": "141f5ee8-6749-48a4-937d-a0fcfcd1a4ec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed:\n",
      "\" observed solomon, his sister’s question having\n",
      "drawn no answer.\n",
      "\n",
      "“what, blue-coat land?” said mrs. w \"\n",
      "anled was a feet th the hasd and toeer the wese and the saee to her aod the saee to her aod toeer the wese an an and the saee to her aod toeer the wese an an and the saee to her aod toeer the wese an an and the saee to her aod toeer the wese an an and the saee to her aod toeer the wese an an and the saee to her aod toeer the wese an an and the saee to her aod toeer the wese an an and the saee to her aod toeer the wese an an and the saee to her aod toeer the wese an an and the saee to her aod toeer the wese an an and the saee to her aod toeer the wese an an and the saee to her aod toeer the wese an an and the saee to her aod toeer the wese an an and the saee to her aod toeer the wese an an and the saee to her aod toeer the wese an an and the saee to her aod toeer the wese an an and the saee to her aod toeer the wese an an and the saee to her aod toeer the wese an an and the saee to her aod toeer the wese an an and the saee to her aod toeer the wese an an and the saee to her aod toeer th"
     ]
    }
   ],
   "source": [
    "# generate text\n",
    "start_index = random.randint(0, len(dataX)-1)\n",
    "pattern = dataX[start_index]\n",
    "print(\"Seed:\")\n",
    "print(\"\\\"\", ''.join([int_to_char[value] for value in pattern]), \"\\\"\")\n",
    "for i in range(1000):\n",
    "    x = np.reshape(pattern, (1, len(pattern), 1))\n",
    "    x = x / float(len(chars))\n",
    "    prediction = model.predict(x, verbose=0)\n",
    "    index = np.argmax(prediction)\n",
    "    result = int_to_char[index]\n",
    "    seq_in = [int_to_char[value] for value in pattern]\n",
    "    sys.stdout.write(result)\n",
    "    pattern.append(index)\n",
    "    pattern = pattern[1:len(pattern)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "skm4OqJKbe-8"
   },
   "outputs": [],
   "source": [
    "import pickle as pkl \n",
    "pkl.dump(model, open('/content/drive/MyDrive/New folder/final_model1.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8WfsLFJcANhA"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
